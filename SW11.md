# ğŸ“˜ Woche 11 â€“ Daten aggregieren & Gruppenoperationen

Woche 11 behandelt das systematische **Gruppieren, Aggregieren und Pivotieren** von Daten.  
Diese Techniken ermÃ¶glichen es, Daten effizient nach Kategorien zu analysieren, Verteilungen zu untersuchen und Trends sichtbar zu machen.

---

## ğŸ”§ 1. Grundprinzip: Aggregation mit `groupby()`

`groupby()` teilt einen DataFrame in Gruppen ein und erlaubt dann Aggregationen wie `mean()`, `median()`, `sum()`, `count()` oder mehrere gleichzeitig mit `agg()`.

**Beispiel: Mittlere Zylinderzahl nach Herkunft**
```python
Auto.cylinders.groupby(Auto.origin).mean()
```

---

## ğŸ“ˆ 2. Mehrdimensionale Gruppierungen

### Beispiel: Durchschnittliche Kraftstoffeffizienz (mpg) nach Jahr und Herkunft
```python
Entwicklung_MPG = Auto.mpg.groupby([Auto.year, Auto.origin]).mean()
```

### Umwandeln in Tabellenform (Wide-Format) mit `unstack()`
```python
Entwicklung_MPG_df = Entwicklung_MPG.unstack()
```

### Plot:
```python
Entwicklung_MPG_df.plot(title='Mittlere Kraftstoffeffizienz nach Herkunft')
```

**Wichtige Erkenntnis:**  
Nach der Ã–lkrise 1973 stieg die Effizienz deutlich â€” USA hinkt Europa und Japan hinterher.

---

## ğŸ§± 3. Pivot-Tabellen (`pivot_table()`)

`pivot_table()` ist eine bequeme Alternative zu `groupby()` + `unstack()`.

```python
Auto.pivot_table(values='mpg', index='year', columns='origin').round(2)
```

---

## ğŸ“Š 4. Aggregationsfunktionen â€“ Verteilungen & Kennzahlen

### Quantile berechnen
```python
dflohn.groupby('Geschlecht').Lohn.quantile([0.25, 0.5, 0.75]).unstack()
```

### Mean & Median gleichzeitig
```python
dflohn.groupby('Geschlecht').Lohn.agg(['mean', 'median'])
```

Mit Spaltenumbenennung:
```python
dflohn.groupby('Geschlecht').Lohn.agg([
    ('Mittelwert', 'mean'),
    ('Median', 'median')
])
```

---

## ğŸ“… 5. Zeitreihenanalyse: BÃ¶rsenindizes

### Einlesen
```python
Indizes = pd.read_csv('hspitr.csv', sep=';', index_col=0, parse_dates=True)
Indizes.sort_index(inplace=True)
```

### Plot
```python
Indizes.plot()
```

**Beobachtung:**  
Small-Cap-Unternehmen entwickelten sich langfristig besser als Large-Caps.

---

## ğŸ“ˆ 6. Renditen analysieren

### Tagesrenditen:
```python
Renditen = Indizes.pct_change().dropna()
```

### Mittelwert & Standardabweichung:
```python
Renditen.agg(['mean', 'std'])
```

### Boxplot:
```python
Renditen[['SPI_Small_Cap','SPI_Large_Cap']].boxplot()
```

---

## ğŸ” 7. Zeitlich aggregierte Auswertungen

### Medianrenditen pro Jahr:
```python
Renditen.groupby(Renditen.index.year).median()
```

### VolatilitÃ¤t pro Jahr:
```python
std_jahr = Renditen.groupby(Renditen.index.year).std()
std_jahr.SPI.plot()
```

**Beobachtung:**  
VolatilitÃ¤t ist in Krisenjahren (z.â€¯B. 2008) deutlich erhÃ¶ht.

---

## ğŸ”¢ 8. HÃ¤ufigkeitstabellen & Kreuztabellen

### Absolute HÃ¤ufigkeiten:
```python
pd.crosstab(Auto.origin, Auto.cylinders, margins=True)
```

### Relative HÃ¤ufigkeiten:
```python
pd.crosstab(Auto.origin, Auto.cylinders, margins=True, normalize=True).round(2)
```

### Bedingte Verteilung (z.â€¯B. bedingt auf Zylinder):
```python
pd.crosstab(Auto.origin, Auto.cylinders, normalize='columns', margins=True).round(2)
```

---

## ğŸ§® 9. Varianz & Kovarianz

### Varianz:
```python
Renditen.SPI.var()
```

### Kovarianzmatrix:
```python
Renditen.cov()
```

---

# âœ… Fazit Woche 11

Du kannst jetzt:

- Daten **gruppieren** und **aggregieren**  
- Mittels `pivot_table()` und `unstack()` Daten umformen  
- Verteilungen und Kennzahlen nach Kategorien analysieren  
- Zeitreihen nach Jahren oder Perioden aggregieren  
- HÃ¤ufigkeitstabellen und Kreuztabellen erstellen  
- Kovarianz & Varianz fÃ¼r Renditen interpretieren  

Diese Werkzeuge sind essenziell fÃ¼r statistische Analysen, Machine Learning und Reporting.
