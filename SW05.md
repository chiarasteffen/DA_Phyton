# 📘 Woche 5 – Daten lesen & schreiben mit Pandas

Diese Woche behandelt den Umgang mit verschiedenen **Dateiformaten** in Pandas:  
Wie man Daten einliest, speichert, mit Fehlwerten umgeht und mit Formaten wie CSV, Excel, Pickle oder STATA arbeitet.

---

## 1. 📁 Einlesen von CSV-Dateien

### Standard-CSV mit Komma als Trennzeichen
```python
import pandas as pd

df = pd.read_csv('daten.csv')
```

### Mit Semikolon getrennt
```python
df = pd.read_csv('daten.csv', sep=';')
```

---

## 2. 📌 Optionen beim Einlesen von CSV-Dateien

- **Kein Header vorhanden**:
```python
df = pd.read_csv('daten.csv', header=None)
```

- **Header manuell setzen**:
```python
df = pd.read_csv('daten.csv', header=None,
                 names=['Name', 'Vorname', 'Geschlecht', 'Gehalt'])
```

- **Nur bestimmte Spalten und Zeilen laden**:
```python
df = pd.read_csv('drinksbycountry.csv',
                 usecols=[0, 4, 5],
                 index_col=0,
                 nrows=4)
```

- **Index-Spalte manuell setzen**:
```python
df = pd.read_csv('daten.csv', index_col=0)
```

---

## 3. 🧪 Flexible Trennung (Whitespace-getrennt)

- Automatisches Erkennen von beliebigen Leerzeichen:
```python
df = pd.read_csv('ex3.txt', sep='\\s+')
```

- Alternative: **Fixed Width Format**:
```python
df = pd.read_fwf('ex3.txt', index_col=0)
```

---

## 4. ❌ Umgang mit Fehlwerten (NaN)

- **Fehlwerte erkennen**:
```python
df.isna()
df.isna().sum()
```

- **Zeilen mit NaN löschen**:
```python
df.dropna(inplace=True)
```

- **Benutzerdefinierte NaN-Werte beim Einlesen definieren**:
```python
df = pd.read_csv('daten.csv', na_values=['fehlend', 'NA', '-'])
```

- **Fehlwerte ersetzen**:
```python
df.fillna(0, inplace=True)   # alle NaNs durch 0 ersetzen
```

---

## 5. 💾 Schreiben von Daten

- **Standard-CSV speichern**:
```python
df.to_csv('output.csv')
```

- **Mit anderem Trennzeichen**:
```python
df.to_csv('output.csv', sep='|')
```

- **Fehlwerte ersetzen beim Speichern**:
```python
df.to_csv('output.csv', na_rep='MISSING')
```

- **Ohne Index speichern**:
```python
df.to_csv('output.csv', index=False)
```

---

## 6. 🥒 Binärformat: Pickle

Pickle speichert Pandas-Objekte effizient im Binärformat (nicht für Archivierung geeignet!).

- **Speichern**:
```python
df.to_pickle('daten.pkl')
```

- **Laden**:
```python
df = pd.read_pickle('daten.pkl')
```

---

## 7. 📊 Excel-Dateien

- **Standardblatt einlesen**:
```python
df = pd.read_excel('datei.xlsx')
```

- **Bestimmtes Tabellenblatt einlesen**:
```python
df = pd.read_excel('datei.xlsx', sheet_name='Tabelle2', index_col=0)
```

- **Als Excel speichern**:
```python
df.to_excel('output.xlsx', index=False)
```

> 💡 Excel-Export benötigt das Paket `openpyxl` (für `.xlsx`).

---

## 8. 📚 Weitere unterstützte Formate

Pandas unterstützt viele Dateiformate:

| Format     | Funktion                 |
|------------|--------------------------|
| JSON       | `pd.read_json()`         |
| STATA      | `pd.read_stata()`        |
| SAS/SPSS   | über Zusatzpakete        |
| SQL        | `pd.read_sql()`          |

### Beispiel: STATA-Datei einlesen
```python
df = pd.read_stata('daten.dta')
```

---

## 9. 🌐 Daten aus dem Internet laden

Daten können direkt aus URLs geladen werden:

```python
url = "https://raw.githubusercontent.com/datensatz.csv"
df = pd.read_csv(url)
```

> ⚠️ Falls HTTPS nicht unterstützt wird, kann ein SSL-Fehler auftreten.

---

## 10. 🧠 Best Practices

- Immer `index_col` bewusst setzen oder ausschließen (z. B. bei Zeitreihen).
- Immer auf **Konsistenz von Trennzeichen** achten (`sep=';'` vs `','`).
- Dateiformate mit NaNs immer mit `na_values` oder `fillna` behandeln.
- Binärformate (Pickle) nie langfristig speichern → nur temporär zur Performance.
- Große Excel-Dateien → nur benötigte Blätter/Spalten laden.

---

## ✅ Fazit Woche 5

Diese Woche vermittelt essentielle Fähigkeiten zum **Einlesen, Schreiben und Bearbeiten von Daten in verschiedenen Formaten**.

Du kannst jetzt:

- **CSV-Dateien** robust einlesen und exportieren
- **Fehlwerte** erkennen, behandeln und gezielt ersetzen
- mit **Excel**- und **Pickle-Dateien** effizient arbeiten
- Daten aus **exotischen Formaten (STATA, JSON)** einlesen
- Dateistrukturen erkennen und analysieren

👉 Diese Techniken sind Grundlage für alle weiteren Schritte in der Datenanalyse.
